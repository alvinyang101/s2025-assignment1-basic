{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "from ece496b_basics.adapters import *\n",
    "from ece496b_basics.model import CustomModule\n",
    "from ece496b_basics.generator import generate_text\n",
    "\n",
    "DATA_PATH = Path(\"../data\").resolve()\n",
    "OUTPUT_PATH = Path(\"outputs\").resolve()\n",
    "CHECKPOINT_DIR = Path(\"checkpoints\").resolve()\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ts_tokenized_path = OUTPUT_PATH / \"tinystories_encoded.npy\"\n",
    "ts_vocab_path = OUTPUT_PATH / \"tinystories_vocab.pkl\"\n",
    "ts_merges_path = OUTPUT_PATH / \"tinystories_merges.pkl\"\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Weights & Biases\n",
    "config = {\n",
    "    \"vocab_size\": 10_000,\n",
    "    \"context_length\": 128,\n",
    "    \"d_model\": 512,\n",
    "    \"num_layers\": 4,\n",
    "    \"num_heads\": 16,\n",
    "    \"d_ff\": 2048,\n",
    "    \"attn_pdrop\": 0.1,\n",
    "    \"residual_pdrop\": 0.1,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_epochs\": 5,\n",
    "    \"epochs_per_checkpoint\": 5,\n",
    "    \"steps_per_epoch\":  2500,\n",
    "    \"learning_rate\": 0.001,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "wandb.init(project=\"training_together\", config=config)\n",
    "config = wandb.config\n",
    "dataset = np.load(ts_tokenized_path, mmap_mode=\"r\")\n",
    "model = CustomModule(\n",
    "    vocab_size=config.vocab_size,\n",
    "    context_length=config.context_length,\n",
    "    d_model=config.d_model,\n",
    "    num_layers=config.num_layers,\n",
    "    num_heads=config.num_heads,\n",
    "    d_ff=config.d_ff,\n",
    "    device=device,\n",
    ")\n",
    "optimizer = get_adamw_cls()(model.parameters(), lr=config.learning_rate)\n",
    "# scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "# optimizer, lr_lambda=lambda it: run_get_lr_cosine_schedule(\n",
    "#     it, learning_rate, learning_rate * 0.1, 1000, 10000)\n",
    "# )\n",
    "total_loss = 0\n",
    "for epoch in range(config.num_epochs):\n",
    "    for step in range(config.steps_per_epoch):\n",
    "        inputs, targets = run_get_batch(dataset, config.batch_size, config.context_length, device)\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        # Compute loss\n",
    "        loss = run_cross_entropy(outputs.view(-1, config.vocab_size), targets.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        run_gradient_clipping(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        wandb.log({f\"Loss:\": loss.item(), \"epoch\": epoch})\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{config.num_epochs}, Total Loss: {total_loss}\")\n",
    "    # Save checkpoint\n",
    "    if epoch % config.epochs_per_checkpoint == 0:\n",
    "        run_save_checkpoint(model, optimizer, epoch, f\"checkpoint_epoch_{epoch}.pt\")\n",
    "\n",
    "# Save final checkpoint if not already saved\n",
    "if epoch % config.epochs_per_checkpoint != 0:\n",
    "    run_save_checkpoint(model, optimizer, epoch, CHECKPOINT_DIR / f\"checkpoint_epoch_{epoch}.pt\")\n",
    "# Finish wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Some Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given prompt: Mitochondria\n",
      "Generated:\n",
      "Mitochondria. She was very excited to go to the park and play.\n",
      "When she arrived at the park, she saw a big, green tree. She wanted to climb it and see what was on the other side. She started to climb the tree, but she was scared. She didn't want to get stuck.\n",
      "Suddenly, she heard a voice. It was her mom. She said, \"Don't be scared, I'm here to help you.\" She took a deep breath and started to climb the tree.\n",
      "When she was at the top, she saw a beautiful park with lots of trees and flowers. She was so happy! She ran around and explored the park, and she had a wonderful time.\n",
      "<|endoftext|>\n",
      "Once upon a time, there was a little girl named Lily. Lily loved to play with her toys and eat yummy food. One day, she found a big box in her room. She was very curious about what was inside.\n",
      "Lily opened the box and found a small, shiny toy. It was a magic wand! The wand could make things shrink. Lily was very excited and showed the wand to her mom. Her mom said, \"Wow, Lily! That's a magic wand!\"\n",
      "Lily and her mom went to the park to\n"
     ]
    }
   ],
   "source": [
    "# model = CustomModule(\n",
    "#     vocab_size=config.vocab_size,\n",
    "#     context_length=config.context_length,\n",
    "#     d_model=config.d_model,\n",
    "#     num_layers=config.num_layers,\n",
    "#     num_heads=config.num_heads,\n",
    "#     d_ff=config.d_ff,\n",
    "#     device=device,\n",
    "# )\n",
    "# optimizer = get_adamw_cls()(model.parameters(), lr=config.learning_rate)\n",
    "# load_checkpoint(f\"checkpoint_epoch_{config.num_epochs-1}.pt\")\n",
    "tokenizer = from_files(ts_vocab_path, ts_merges_path, special_tokens=[\"<|endoftext|>\"])\n",
    "prompt = \"Mitochondria\"\n",
    "text = generate_text(model, tokenizer, prompt, max_tokens=256, temperature=0.1, top_p=0.9, device=\"cuda\")\n",
    "print(f\"Given prompt: {prompt}\")\n",
    "print(f\"Generated:\\n{text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece496b_basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
